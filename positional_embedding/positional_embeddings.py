import torch
import nltk
#nltk.download('punkt')  ## uncomment if running for the first time

class PositionalEmbedding:
    def __init__(self, data_path):
        pass
    
    def get_vanilla_word_emb(self, word):
        pass
    
    def get_vanilla_pos_emb(self, position):
        pass
    
    def get_positional_embedding(self, word_emb, positional_emb):
        pass

    @staticmethod
    def compute_similarity(embedding1, embedding2):
        pass

if __name__ == "__main__":
    PositionalEmbedding(data_path)
    print('hello')